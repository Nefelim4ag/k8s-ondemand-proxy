image:
  repository: ghcr.io/nefelim4ag/k8s-ondemand-proxy
  tag: 0.0.2
  pullPolicy: IfNotPresent
  imagePullSecrets: []

hpa:
  enabled: false
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 85
  behavior:
    scaleDown:
      policies:
      - type: Pods
        value: 1
        periodSeconds: 30

## @param strategy [object] Strategy to use to update Pods
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
##
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 5%
    maxUnavailable: 10%

service:
  annotations: {}
  type: ClusterIP
  clusterIP: {}
  ports:
    - name: tcp
      protocol: TCP
      port: 1001
      targetPort: tcp

ports:
  - name: tcp
    containerPort: 1001

command: []

resources:
  requests:
    cpu: 0.005
    memory: 16Mi

## @param env dict of environment variables to set in container
env:
  GOMAXPROCS: "2"
  CONFIGPATH: /etc/config/config.yaml
  NAMESPACE:
    valueFrom:
      fieldRef:
        fieldPath: metadata.namespace
  POD_IP:
    valueFrom:
      fieldRef:
        fieldPath: status.podIP

config:
  namespace: "{{ .Release.Namespace }}"
  replicas: 1
  idle-timeout: 15m
  resource: statefulset/app
  proxy:
  - local: ":1001"
    remote: "app.namespace.svc.cluster.local:1001"

hostNetwork: false

## Pod Disruption Budget configuration in distributed mode.
## @param pdb.minAvaliable how many pods must be available to proceed with deployment
## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
##
pdb:
  enabled: false
  minAvailable: 50%

## @param livenessProbe
## Will restart pod on liveness fail
livenessProbe:
  null
  # httpGet:
  #   path: /
  #   port: http

## @param readinessProbe
## Will stop route requests to pod on fail
readinessProbe:
  null
  # httpGet:
  #   path: /
  #   port: http

## @param startupProbe
## Will delay execution of readiness/liveness probe until success
## On fail will restart pod
startupProbe:
  null
  # httpGet:
  #   path: /
  #   port: http

terminationGracePeriodSeconds: 30
lifecycle:
  preStop:
    exec:
      ## sleep is hacky solution to allow traffic drain on termination
      command:
        - sh
        - -c
        - "sleep 15; kill 1"

minReadySeconds: 10

dnsConfig: {}

deployment:
  annotations: {}
  ## @param deployment.replicas will be ignored if hpa enabled
  replicas: 1

pod:
  annotations: {}
  labels: {}

volumeMounts:
- name: config
  mountPath: /etc/config/
volumes:
- name: config
  configMap:
    name: "{{ $.Release.Name }}"
    defaultMode: 0644

initContainers:
  []
  # - name: share
  #   image: example:latest
  #   imagePullPolicy: Always
  #   command:
  #     - "bash"
  #     - "-exc"
  #     - |
  #       {
  #         echo lol;
  #       }
  #   volumeMounts:
  #     - mountPath: /data
  #       name: disk

affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 1
      preference:
        matchExpressions:
        - key: app
          operator: In
          values:
          - "{{ .Release.Name }}"

tolerations:
  - key: "{{ .Release.Name }}"
    operator: Exists

topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: ScheduleAnyway
    labelSelector:
      matchLabels:
        app: "{{ .Release.Name }}"
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: ScheduleAnyway
    labelSelector:
      matchLabels:
        app: "{{ .Release.Name }}"
